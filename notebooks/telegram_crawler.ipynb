{
 "cells": [
  {
   "cell_type": "code",
   "id": "8f317781-b2c4-4d16-959f-bd9f46670712",
   "metadata": {},
   "source": [
    "import os\n",
    "import sys\n",
    "app_path = os.path.abspath('..')\n",
    "sys.path.insert(0, app_path)\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from app.telegram_client import get_client_with_auth\n",
    "from app.chroma_client import get_embeddings, get_client, load_data_to_chroma\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "CHANNEL_NAME = os.getenv('TELEGRAM_CHAT_NAME')\n",
    "CHANNEL_ID = os.getenv('TELEGRAM_CHAT_ID')\n",
    "\n",
    "try:\n",
    "    CHANNEL_ID = int(CHANNEL_ID)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "print(f\"Channel id: {CHANNEL_ID}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "55201826-4a8d-4ba2-a0d0-e29f5e925922",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "telegram_client = await get_client_with_auth()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "963d0f92-1614-4eaa-bda4-c9d50ea26423",
   "metadata": {},
   "source": [
    "from typing import Any\n",
    "from tqdm import tqdm\n",
    "from telethon.tl.types import PeerChannel\n",
    "\n",
    "CHAT_MESSAGES_LIMIT = 1000\n",
    "\n",
    "async def get_messages_from_channel(\n",
    "    telegram_client, channel_id: int | str, min_id: int = 0, max_id: int = 0, chunks: int = 10\n",
    ") -> dict[int, dict[str, Any]]:\n",
    "    messages_data = {}\n",
    "    if isinstance(channel_id, int) and channel_id < 0:\n",
    "        channel_id = PeerChannel(channel_id)\n",
    "\n",
    "    channel = await telegram_client.get_entity(channel_id)\n",
    "    last_seen_message_id = max_id\n",
    "\n",
    "    for _i in tqdm(range(chunks), desc=\"Fetching chunks\", position=0, leave=False, colour='green'):\n",
    "        if all((last_seen_message_id, min_id)) and last_seen_message_id == min_id:\n",
    "            print(\"Reached last unseen message\")\n",
    "            break\n",
    "\n",
    "        async for message in telegram_client.iter_messages(\n",
    "            channel, min_id=min_id, offset_id=last_seen_message_id, limit=CHAT_MESSAGES_LIMIT\n",
    "        ):\n",
    "            if not message.text or len(message.text) < 10:\n",
    "                continue\n",
    "\n",
    "            message_text = message.text\n",
    "            if message.is_reply:\n",
    "                if message.reply_to_msg_id not in messages_data:\n",
    "                    original_message = await message.get_reply_message()\n",
    "                    if original_message:\n",
    "                        messages_data[original_message.id] = {\n",
    "                            'text': original_message.text,\n",
    "                            'metadata': {\n",
    "                                'sender_name': original_message.sender.username or '',\n",
    "                                'id': original_message.id,\n",
    "                                'date_str': original_message.date.isoformat(),\n",
    "                                'date': original_message.date.timestamp(),\n",
    "                            }\n",
    "                        }\n",
    "\n",
    "                original_message = messages_data.get(message.reply_to_msg_id)\n",
    "                if original_message:\n",
    "                    message_text = f'>> {original_message['text']}\\n\\n {message.text}'\n",
    "                else:\n",
    "                    message_text = f'>> [[ORIGINAL MESSAGE REMOVED]]\\n\\n {message.text}'\n",
    "\n",
    "            messages_data[message.id] = {\n",
    "                'text': message_text,\n",
    "                'metadata': {\n",
    "                    'sender_name': message.sender.username or '',\n",
    "                    'id': message.id,\n",
    "                    'date': message.date.timestamp(),\n",
    "                }\n",
    "            }\n",
    "\n",
    "        last_seen_message_id = message.id\n",
    "        if last_seen_message_id == 0:\n",
    "            break\n",
    "\n",
    "    return messages_data"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c07b9ed61b941097",
   "metadata": {},
   "source": [
    "# ru_model_name = \"cointegrated/rubert-tiny2\"\n",
    "ru_model_name = \"intfloat/multilingual-e5-large\"\n",
    "embeddings = get_embeddings(ru_model_name)\n",
    "\n",
    "chroma_client_from_telegram = get_client(f'telegram_{CHANNEL_NAME}', embeddings)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4a20bf214491fdc4",
   "metadata": {},
   "source": [
    "from langchain_chroma import Chroma\n",
    "from datetime import datetime, timedelta, UTC\n",
    "\n",
    "def get_last_seen_id_from_db(chroma_client: Chroma):\n",
    "    doc_dict = chroma_client.get(\n",
    "        where={\"date\": {\"$gte\": (datetime.now(UTC) - timedelta(days=30)).timestamp()}},\n",
    "        include=['metadatas'],\n",
    "    )\n",
    "    if not doc_dict['metadatas']:\n",
    "        return 0\n",
    "\n",
    "    return max(meta['id'] for meta in doc_dict['metadatas'])\n",
    "\n",
    "def get_earliest_message_id(chroma_client: Chroma):\n",
    "    doc_dict = chroma_client.get(include=['metadatas'])\n",
    "    if not doc_dict['metadatas']:\n",
    "        return 0\n",
    "\n",
    "    return min(meta['id'] for meta in doc_dict['metadatas'])\n",
    "\n",
    "async def get_early_messages_from_chat(channel_id, telegram_client, chroma_client: Chroma, chunks=10):\n",
    "    earliest_message_id = get_earliest_message_id(chroma_client)\n",
    "    print(\"Earliest seen id:\", earliest_message_id)\n",
    "    messages = await get_messages_from_channel(\n",
    "        telegram_client, channel_id, max_id=earliest_message_id, chunks=chunks\n",
    "    )\n",
    "    print(\"Got messages:\", len(messages))\n",
    "    return messages\n",
    "\n",
    "async def get_last_messages_from_chat(channel_id, telegram_client, chroma_client: Chroma, chunks=10):\n",
    "    last_seen_id = get_last_seen_id_from_db(chroma_client)\n",
    "    print(\"Last seen id:\", last_seen_id)\n",
    "    messages = await get_messages_from_channel(telegram_client, channel_id, min_id=last_seen_id, chunks=chunks)\n",
    "    print(\"Got messages:\", len(messages))\n",
    "    return messages"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "77f01eb8bd86c1e3",
   "metadata": {},
   "source": [
    "new_messages = await get_last_messages_from_chat(\n",
    "    channel_id=CHANNEL_ID,\n",
    "    telegram_client=telegram_client,\n",
    "    chroma_client=chroma_client_from_telegram,\n",
    "    chunks=10\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8898e8b20bfe1503",
   "metadata": {},
   "source": [
    "new_messages = await get_early_messages_from_chat(\n",
    "    channel_id=CHANNEL_ID,\n",
    "    telegram_client=telegram_client,\n",
    "    chroma_client=chroma_client_from_telegram,\n",
    "    chunks=10\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "81f10ccfbddd2640",
   "metadata": {},
   "source": [
    "print(len(new_messages))\n",
    "print(list(new_messages.values())[-1:])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6185e4f8b26c83d4",
   "metadata": {},
   "source": [
    "load_data_to_chroma(chroma_client_from_telegram, new_messages.values(), reset=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "28b19e1229e17113",
   "metadata": {},
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "\n",
    "llm_qwen3_8b = ChatOllama(\n",
    "    model=\"qwen3:8b\",\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e297c8c001160326",
   "metadata": {},
   "source": [
    "user_query = \"Выведи самые токсичные сообщения в чате.\"\n",
    "user_query = \"Выведи самые позитивные сообщения в чате.\"\n",
    "user_query = \"Можно ли компенсировать отель или аквапарк через велнес БТА или BTA?\"\n",
    "user_query = \"Как получить детские деньги, компенсацию по уходу за ребенком.\"\n",
    "user_query = \"Тенденции рынка недвижимости на Кипре\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "22ee47275f8e0136",
   "metadata": {},
   "source": [
    "ru_telegram_prompt_expanding = PromptTemplate(\n",
    "    input_variables=[\"user_query\", \"n\"],\n",
    "    template=\"\"\"\n",
    "    Напиши {n} гипотетических ответов на запрос пользователя.\n",
    "    Не добавляй заголовков, авторов и другой дополнительной информации к твоим ответам.\n",
    "\n",
    "    Вопрос пользователя:\n",
    "    {user_query}\n",
    "\n",
    "    Гипотетические ответы:\n",
    "    \"\"\",\n",
    ")\n",
    "\n",
    "hyde_chain_r1_8b = ru_telegram_prompt_expanding | llm_qwen3_8b\n",
    "raw_hypothetical_answers = hyde_chain_r1_8b.invoke({\"user_query\": user_query, \"n\": 15}).content\n",
    "raw_hypothetical_answers"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6101aae10854f429",
   "metadata": {},
   "source": [
    "user_query = raw_hypothetical_answers.split('</think>', maxsplit=1)[-1]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8725e1806b105426",
   "metadata": {},
   "source": [
    "related_docs = chroma_client_from_telegram.similarity_search_with_relevance_scores(user_query, k=15)\n",
    "related_docs"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7f991057712c0313",
   "metadata": {},
   "source": [
    "\n",
    "from datetime import datetime, timedelta, UTC\n",
    "\n",
    "related_docs = chroma_client_from_telegram.get(\n",
    "    where={\"date\": {\"$gte\": (datetime.now(UTC) - timedelta(days=30)).timestamp()}},\n",
    ")\n",
    "meta_docs = list(zip(related_docs['metadatas'], related_docs['documents']))\n",
    "\n",
    "context = \"\\n\\n---\\n\\n\".join(f\"{meta['date']} - {meta['sender_name']}: {doc}\" for meta, doc in meta_docs)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2060e3f298db28c5",
   "metadata": {},
   "source": [
    "len(related_docs['metadatas'])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4ff200e9aa4e6a1c",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "filtered_related_docs = filter(lambda doc_score: doc_score[-1] > 0.3, related_docs)\n",
    "\n",
    "t_link_base = \"https://web.telegram.org/k/#?tgaddr=tg%3A%2F%2Fprivatepost%3Fchannel%3D1133953167%26post%3D\"\n",
    "\n",
    "print(\"\\n\\n---\\n\\n\".join(f\"\"\"\n",
    "{doc.metadata['date']} {t_link_base}{doc.metadata['id']} - {doc.page_content}\n",
    "\"\"\" for doc, _score in filtered_related_docs))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c35007263ed6b21d",
   "metadata": {},
   "source": [
    "filtered_related_docs = filter(lambda doc_score: doc_score[-1] > 0.3, related_docs)\n",
    "\n",
    "context = \"\\n\\n---\\n\\n\".join(f\"{doc.metadata['date']} - {doc.page_content}\" for doc, _score in filtered_related_docs)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bff1b4fc98c216be",
   "metadata": {},
   "source": [
    "# user_query = \"Здесь собраны последние сообщения из чата. Расскажи про основные темы и выводы.\"\n",
    "\n",
    "ru_telegram_prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"user_query\"],\n",
    "    template=\"\"\"\n",
    "    Ты полезный AI ассистент, который отвечает на вопросы пользователя на основе контекста.\n",
    "    Контекст это релевантные вопросу сообщения из телеграм чата.\n",
    "\n",
    "    Контекст:\n",
    "    {context}\n",
    "\n",
    "    Вопрос пользователя:\n",
    "    {user_query}\n",
    "\n",
    "    Если в контексте недостаточно информации, чтобы ответить на вопрос пользователя, то скажи, что недостаточно информации.\n",
    "\n",
    "    Ответ:\n",
    "    \"\"\",\n",
    ")\n",
    "\n",
    "hyde_chain_r1_8b = ru_telegram_prompt | llm_qwen3_8b\n",
    "llm_response = hyde_chain_r1_8b.invoke({\"user_query\": user_query, \"context\": context}).content\n",
    "print(llm_response)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "91144e5909477f78",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
